from util import *
from dynamic_parser import DynamicParser
from node import Node
from op import OP, OP_MANAGER
from parsimonious.grammar import Grammar

DYNAMIC_PARSER_HEADER = """\
from util import *
from node import *"""

content_filter = lambda n: n.t or n.c
content_reducer = lambda n: not n.t
def P2N(p, F=content_filter, R=content_reducer):
    args = F, R
    if p.expr_name.startswith('__'):
        return Node('__')
    if p.expr_name.endswith('_'):
        return Node(p.expr_name, 
            p.children and
                á’(á¦, (P2N(x, *args).txt for x in p.children)) 
            or 
                p.text)
    
    C = []
    for n in p.children:
        n = P2N(n, *args)
        if n.t.startswith('__') or F and not F(n):
            continue
        if not n.S and (n.t.startswith('_') or R and R(n)):
            C.extend(n.c)
            continue
        C.append(n)
    return Node(p.expr_name, C if p.children else p.text)

class Lang:
    rgx4grammar = SMD(lambda x: á–‡(á–‡(x, '"', '\\"'), '\\', '\\\\'))
    
    @staticmethod
    def modchk(tier, mod, R):
        if 'I' in mod:
            mod.discard('I')
            R = R | tier
        return R
    
    def gen_norm_ops(ğ•Š, op_norm):
        ops = {}
        for tier in op_norm:
            consume = set(ops.keys())
            for op_t, mod in tier:
                food = ğ•Š.modchk({x[0] for x in tier}, mod, consume)
                
                kw = {}
                if 'B' in mod:
                    kw['L'] = kw['R'] = food
                else:
                    if 'S' in mod: kw['L'] = food
                    if 'P' in mod: kw['R'] = food
                f = lambda l=á—œ, r=á—œ: f"({op})[{l=} {r=}]"
                op = OP(op_t, mod, f=f, **kw)
                ops[op_t] = op
        return ops
    
    def gen_spec_ops(ğ•Š, op_spec, ops):
        gen_ops = {}
        for L, (op_t, mod), R in op_spec:
            for c in ops:
                if not L or c in ops[L].L|ops[L].R:
                    if (O := ops[c]).PB:
                        O.R.add(op_t)
                if not R or c in ops[R].L|ops[R].R:
                    if (O := ops[c]).SB:
                        O.L.add(op_t)
            
            kw = {}
            if L: kw['L'] = (ops.keys()-ops[L].L)|{L}
            if R: kw['R'] = ğ•Š.modchk(
                {x[1][0] for x in op_spec},
                mod, (ops.keys()-ops[R].R)|{R})
            
            f = lambda l=á—œ, r=á—œ: f"({op})[{l=} {r=}]"
            op = OP(op_t, mod, f=f, **kw)
            
            gen_ops[op_t] = op
        return gen_ops
    
    def parse_secs(ğ•Š, secs):
        secs = á’(Å„, á´(âµ, âµ‰(á–‡(á–‡(secs, "â›\n", Å›), 'â‰', Å„), Å„)))
        op_norm, op_spec, var_spec, keywords, *_ = (âµ‰(x, Å„) for x in re.split(r'\n{2,}', secs))
        op_norm, var_spec = á´(âµ‰, op_norm), set(á´(âµ, var_spec))
        def parse_oper_dec(x, *, rgx=re.compile(á–‡("([^ğ•©]+)([ğ•©]*)", 'ğ•©', SCRIPT.CHAR_SUP))):
            x, y = rgx.match(x).groups()
            return x, set(SCRIPT.sup2nrm(y))
        
        op_norm = á´á´(2, parse_oper_dec, op_norm)
        
        tmp = lambda x,y,z: [x, parse_oper_dec(y), z]
        op_spec = [tmp(*á´(âµ, âµ‰(i, 'ï½œ'))) for i in op_spec]
        
        return op_norm, op_spec, var_spec, keywords
    
    def parse_gram(ğ•Š, gram, rgxs):
        for f, r in rgxs.items():
            gram = á–‡(gram, f"%{f}%", ğ•Š.rgx4grammar(r))
        return Grammar(gram)
    
    def parse_lang(ğ•Š, raw):
        temp, gram = raw.split("Â«GRAMMARÂ»", 1)
        secs, code = temp.split("Â«GENERATORSÂ»", 1)
        
        op_norm, op_spec, var_spec, keywords = ğ•Š.parse_secs(secs)
        ops = ğ•Š.gen_norm_ops(op_norm)
        ops |= ğ•Š.gen_spec_ops(op_spec, ops)
        
        gen_rgx = lambda x: rgx_or(sorted(x, key=âµŒ, reverse=â´³))
        rgxs = { "VAR_SPECIAL": gen_rgx(var_spec),
                   "OPERATORS": gen_rgx(ops.keys()),
                    "KEYWORDS": gen_rgx(keywords) }
        gram = ğ•Š.parse_gram(gram, rgxs)
        
        dynamic_parsers = DynamicParser(ğ•Š, DYNAMIC_PARSER_HEADER + '\n' + code)
        
        return ops, gram, dynamic_parsers
    
    def __init__(ğ•Š, lang_file):
        lang_t = R(lang_file)
        ğ•Š.ops, ğ•Š.gram, ğ•Š.dynamic_parsers = ğ•Š.parse_lang(lang_t)
    
    def general_one_time_manip(ğ•Š, n):
        # responsible for metasyntactical manipulations,
        # ex. making subscripts/superscripts easier to work with
        if not n.S:
            n.c = á´(ğ•Š.general_one_time_manip, n.c)
        match n.t:
            case "supscript": n.c = SCRIPT.sup2nrm(n.c)
            case "subscript": n.c = SCRIPT.sub2nrm(n.c)
        return n
    
    def _apply_tree_manip(ğ•Š, m, n):
        N = n.copy()
        if m.recurse_children == 'B' and not N.S:
            N.c = á´(ğ•Š.lang_tree_manip, N.c)
        N = m(n)
        if m.recurse_children == 'A' and not N.S:
            N.c = á´(ğ•Š.lang_tree_manip, N.c)
        return N
    
    def lang_tree_manip(ğ•Š, N):
        if m := ğ•Š.dynamic_parsers.get_replacement(N.t):
            return ğ•Š._apply_tree_manip(m, N)
        if N.S:
            return N
        
        cc = []
        for n in N.C:
            if m := ğ•Š.dynamic_parsers.get_reduction(N.t):
                assert m.recurse_children != 'A'
                cc.extend(ğ•Š._apply_tree_manip(m, n))
            else:
                cc.append(ğ•Š.lang_tree_manip(n))
        return Node(N.t, cc)
        
    def gen_as(ğ•Š, n, t=á—œ):
        if t is á—œ:
            t = n.t
        
        # print(f"Generating {n} as '{t}'")
        return "asd"
    
    def parse_as(ğ•Š, p, content, **kw):
        gram = ğ•Š.gram[p]
        p = P2N(gram.parse(content), **kw)
        return p
    
    def clean_comments(ğ•Š, content):
        return ğ•Š.parse_as("parser_comment", content, F=lambda n: n.t != "comment").txt
    
    def parse_content(ğ•Š, content):
        n = ğ•Š.parse_as("parser_main", content)
        n.print()
        n = ğ•Š.general_one_time_manip(n)
        n = ğ•Š.lang_tree_manip(n)
        n.print()
        return ğ•Š.gen_as(n)
    
    def __call__(ğ•Š, content_file):
        content = R(content_file)
        if "parser_comment" in ğ•Š.gram:
            content = ğ•Š.clean_comments(content)
        content = ğ•Š.parse_content(content)
        return content

l = Lang("cpy.lang")
l("test.txt")

# N: Nullary
# S: Suffix
# P: Prefix
# B: Binary
# I: Include self in right subgrouping (Right assoc.)