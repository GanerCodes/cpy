from parsimonious.grammar import Grammar
from functools import reduce
from keyword import kwlist, softkwlist
from regex import escape as re_escape

R = lambda x: open(x).read()
HX = lambda c: hex(ord(c))[2:]

flat = lambda x: reduce(lambda x,y: x+y, l:=list(x), type(l[0])() if len(l) else [])

py_bad_string_chr = lambda s, bad="\\\"'{}": s in bad
py_escape_char    = lambda c, pre='': pre+HX(c) if py_bad_string_chr(c) else c

py_escape_string  = lambda s: ''.join(py_escape_char(c, '\\u') for c in s)
py_escape_var     = lambda s: ''.join('_'+py_escape_char(c) for c in s)

py_special_mapper = lambda c, m=dict(zip("ğ—»ğ˜€ğ˜","nst")): '\\'+m[c]

class Node:
    def name_filter(n):
        return n and not n.startswith('_') \
               and n not in ("expr", )
    from_grammar = lambda n: Node(n.text,
            n.expr_name if Node.name_filter(n.expr_name) else "",
            [C for c in n.children if (C:=Node.from_grammar(c)).text])
    def __init__(ğ•Š, text, expr_name, children):
        ğ•Š.text = text
        ğ•Š.expr_name = expr_name
        ğ•Š.children = children
    def __repr__(ğ•Š):
        return f'{ğ•Š.expr_name}: "{ğ•Š.text}"'
    def reduce(ğ•Š):
        if ğ•Š.expr_name and ğ•Š.expr_name == "var":
            return Node(ğ•Š.text, ğ•Š.expr_name, [])
        return Node(ğ•Š.text, ğ•Š.expr_name, flat(
                    [C] if (C:=c.reduce()).expr_name else
                    (C.children or [Node(C.text, "s", [])]) 
                for c in ğ•Š.children))
    def collapse(ğ•Š):
        n = Node(ğ•Š.text, ğ•Š.expr_name, [C for c in ğ•Š.children if (C:=c.collapse()).text.strip()])
        if len(n.children) == 1:
            c = n.children[0]
            return Node(ğ•Š.text, ğ•Š.expr_name+':'+c.expr_name, c.children)
        return n
    def print(ğ•Š, s='', clean=lambda x: x.replace('\n','Ã±')):
        print(f"{s}{ğ•Š.expr_name} â–º {clean(ğ•Š.text)}")
        if ğ•Š.children and all(c.expr_name == 's' for c in ğ•Š.children):
            return print(s+'  '+"S-CHAIN: "+'Â­â€”'.join(clean(c.text) for c in ğ•Š.children))
        [c.print(s+'  ') for c in ğ•Š.children]
    
    def split_children(ğ•Š, f):
        r, b = [], []
        for c in ğ•Š.children:
            if f(c):
                r, b = r+[b, c], []
            else:
                b += [c]
        return r + [b]
    def split_and_group(ğ•Š, f):
        k = split_children(ğ•Š, f)
        # for 
    
    def reparse(ğ•Š):
        match ğ•Š.expr_name:
            case "exprs":
                print(ğ•Š.split_children(
                    lambda c: c.expr_name == "oper" and c.text in ops[-1]))
                return ğ•Š.text
            case "str_guts":
                return py_escape_string(ğ•Š.text)
            case "str_escape":
                return "'" + py_escape_string(ğ•Š.text[1:]) + "'"
            case "str_sub":
                return "{" + ğ•Š.children[1].reparse() + "}"
            case "special_char":
                return "'" + py_special_mapper(ğ•Š.text) + "'"
            case "special_str":
                r = '"'
                for c in ğ•Š.children[1:-1]:
                    match c.expr_name:
                        case "str_escape":
                            r += py_escape_string(c.text[1:])
                        case "special_char":
                            r += py_special_mapper(c.text)
                        case _:
                            r += c.reparse()
                return r + '"'
            case _: # ex. py_str, s, etc.
                if not ğ•Š.children:
                    return ğ•Š.text
                else:
                    return ''.join(c.reparse() for c in ğ•Š.children)

parse_operations = lambda t: [x.strip().split(' ') for x in t.replace('\n', 'âˆ£').split('âˆ£')]
parse_op_mapping = lambda t: [[y.replace('ğ¬', ' ') for y in x.strip().split(' ')] for x in t.replace('\n', 'âˆ£').split('âˆ£')]
parse_op_customs = lambda t: [x.split(' ') for x in t.split('\n')]

rgx_fmt = lambda x: x.replace('"', '\\"').replace('\\', '\\\\')
rgx_or  = lambda x: '(' + ')|('.join(x) + ')'

ops, opm, opc = R("ops").split('\n\n')
ops, opm, opc = parse_operations(ops), parse_op_mapping(opm), parse_op_customs(opc)

py_keywords = kwlist + softkwlist

rgx_keywords = rgx_or(py_keywords)
rgx_operator = rgx_or(flat([[re_escape(c+'='), re_escape(c)] for c in flat(ops)]))
rgx_specials = rgx_or([re_escape(c) for c in flat(flat(opc))])

gram = R("test.gram")
gram = gram.replace(  "%OPERATORS%", rgx_fmt(rgx_operator))
gram = gram.replace("%VAR_SPECIAL%", rgx_fmt(rgx_specials))
gram = gram.replace("%PY_KEYWORDS%", rgx_fmt(f"({rgx_keywords})(\\Z|[^_a-zA-Z0-9])"))
gram = Grammar(gram)

def clean_comments(content):
    parsed = Node.from_grammar(gram['parser_comment'].parse(content)).reduce()
    return flat(c.text for c in parsed.children if c.expr_name != 'comment')
    
content = R("test.txt")
content = clean_comments(content)

tree = Node.from_grammar(gram.parse(content))
tree = tree.reduce()
tree.collapse().print()
print('-'*50)
print(tree.reparse())